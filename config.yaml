http:
    host: 0.0.0.0
    port: 8080
    allow_cors: true
    with_prometheus: true

log:
    # Comment the following line to disable the logging
    file_path: "./log.log"
    levels:
        oramacore: trace
        orama_js_pool: info

writer_side:
    output:
        type: in-memory
        # type: rabbitmq
        # host: localhost
        # port: 5672
        # user: guest
        # password: guest
        # v_host: /
        # stream_name: oramacore-operations
        # client_provided_name: oramacore-producer
        # producer_name: write

    hooks:
        select_embeddings_properties:
            check_interval: 60s
            max_idle_time: 20s
            instances_count_per_code: 3
            queue_capacity: 100
            max_execution_time: 1s
            max_startup_time: 100ms

    # Replace the following value with your own API key
    master_api_key: my-master-api-key
    config:
        data_dir: ./.data/writer
        # The maximum number of embeddings that can be stored in the queue
        # before the writer starts to be blocked
        # NB: the elements are in memory, so be careful with this value
        embedding_queue_limit: 50000
        # The number of the document insertions after the write side will commit the changes
        insert_batch_commit_size: 50000000
        # The default embedding model used to calculate the embeddings
        # if not specified in the collection creation
        default_embedding_model: BGESmall
        # The maximum number of request to javascript runtime that can be stored in the queue
        # NB: the elements are in memory, so be careful with this value
        javascript_queue_limit: 500000
        # Set interval for commiting the changes to the disk
        commit_interval: 1m

reader_side:
    input:
        type: in-memory
        # type: rabbitmq
        # host: localhost
        # port: 5672
        # user: guest
        # password: guest
        # v_host: /
        # stream_name: oramacore-operations
        # client_provided_name: oramacore-producer
        # consumer_name: reader

    config:
        data_dir: ./.data/reader
        # The number of the write operation after the read side will commit the changes
        insert_batch_commit_size: 50000000
        # Set interval for commiting the changes to the disk
        commit_interval: 1m

ai_server:
    scheme: http
    host: 0.0.0.0
    port: 50051
    api_key: ""
    max_connections: 15
    total_threads: 12

    embeddings:
        default_model_group: all
        dynamically_load_models: false
        execution_providers:
            - CUDAExecutionProvider
            - CPUExecutionProvider
        total_threads: 8

    llm:
        port: 8000
        host: 0.0.0.0
        model: "Qwen/Qwen2.5-3B-Instruct"

    # remote_llms:
    #     - provider: openai
    #       api_key: "sk-"
    #       default_model: "gpt-4o"
    #     - provider: together
    #       api_key: "sk-"
    #       default_model: "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF"
    #     - provider: fireworks
    #       api_key: "sk-"
    #       default_model: "accounts/fireworks/models/llama-v3p1-8b-instruct"
