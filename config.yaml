http:
    host: 0.0.0.0
    port: 8080
    allow_cors: true
    with_prometheus: true

log:
    # Comment the following line to disable the logging
    file_path: "./log.log"
    levels:
        oramacore: trace

writer_side:
    output:
        type: in-memory
        # type: rabbitmq
        # host: localhost
        # port: 5552
        # user: guest
        # password: guest
        # v_host: /
        # stream_name: oramacore-operations
        # client_provided_name: oramacore-producer
        # producer_name: write

    hooks:
        # List of allowed hosts for external HTTP calls from hooks
        # Examples: ["s3.amazonaws.com", "*.s3.amazonaws.com", "storage.googleapis.com"]
        # Empty list (default) means no external HTTP access is allowed
        allowed_hosts: []
        # Timeout for hook initialization (JSExecutor builder) in milliseconds
        # This is how long to wait for the JavaScript runtime to initialize
        builder_timeout_ms: 200
        # Timeout for hook execution in milliseconds
        # This is how long the actual hook code can run (including HTTP calls)
        execution_timeout_ms: 1000

    # Replace the following value with your own API key
    master_api_key: my-master-api-key
    config:
        data_dir: ./.data/writer
        # The maximum number of embeddings that can be stored in the queue
        # before the writer starts to be blocked
        # NB: the elements are in memory, so be careful with this value
        embedding_queue_limit: 50000
        # The number of the document insertions after the write side will commit the changes
        insert_batch_commit_size: 50000000
        # The default embedding model used to calculate the embeddings
        # if not specified in the collection creation
        default_embedding_model: BGESmall
        # The maximum number of request to javascript runtime that can be stored in the queue
        # NB: the elements are in memory, so be careful with this value
        javascript_queue_limit: 500000
        # Set interval for commiting the changes to the disk
        commit_interval: 1m
        # Temporary index cleanup configuration
        temp_index_cleanup:
            # How often to run cleanup (default: 1 hour)
            cleanup_interval: 1h
            # Maximum age before cleanup (default: 12 hours)
            max_age: 12h
            # Enable/disable cleanup (default: true)
            enabled: true
    # Uncomment to allow JWT validation with multiple providers
    # jwt:
    #     providers:
    #         - name: "internal-dashboard"
    #           jwks_url: http://localhost:3000/api/.well-known/jwks.json
    #           issuers:
    #               - http://localhost:3000
    #           audiences:
    #               - http://localhost:8080
    #           refresh_interval: 1h
    #         # Add more providers as needed:
    #         # - name: "auth0-production"
    #         #   jwks_url: https://your-tenant.auth0.com/.well-known/jwks.json
    #         #   issuers:
    #         #       - https://your-tenant.auth0.com/
    #         #   audiences:
    #         #       - https://api.yourservice.com


reader_side:
    # Optional on the reader side
    master_api_key: my-master-api-key

    input:
        type: in-memory
        # type: rabbitmq
        # host: localhost
        # port: 5552
        # user: guest
        # password: guest
        # v_host: /
        # stream_name: oramacore-operations
        # client_provided_name: oramacore-producer
        # consumer_name: reader

    config:
        data_dir: ./.data/reader
        # The number of the write operation after the read side will commit the changes
        insert_batch_commit_size: 50000000
        # Set interval for commiting the changes to the disk
        commit_interval: 1m
        # Each Nth commit will be forced, regardless of per-collection thresholds
        force_commit: 4
        # Per-collection commit thresholds
        # Uncomment to customize (these are the defaults)
        collection_commit:
            # Number of operations before collection commits immediately
            operation_threshold: 300
            # Time since last commit before collection participates in global commit
            time_threshold: 5m

        # offload fields if there's no search on that field in the last 30minutes
        # keeping a window of 2 ^ 4 * 2 ^ 8 seconds = 4096 seconds = ~1 hour
        offload_field:
            unload_window: 30m
            # 2 ^ 8 groups
            slot_count_exp: 8
            # group by 2 ^ 4 seconds
            slot_size_exp: 4

    hooks:
        # List of allowed hosts for external HTTP calls from hooks
        # Examples: ["s3.amazonaws.com", "*.s3.amazonaws.com", "storage.googleapis.com"]
        # Empty list (default) means no external HTTP access is allowed
        allowed_hosts: []
        # Timeout for hook initialization (JSExecutor builder) in milliseconds
        # This is how long to wait for the JavaScript runtime to initialize
        builder_timeout_ms: 200
        # Timeout for hook execution in milliseconds
        # This is how long the actual hook code can run (including HTTP calls)
        execution_timeout_ms: 1000

    # Uncomment to allow analytics
    analytics:
        api_key: my-analytics-api-key
        metadata_from_headers:
            -   header: user-agent
                metadata_key: ua
            -   header: CF-Connecting-IP
                metadata_key: ip
            -   header: CF-IPCountry
                metadata_key: country
            -   header: continent
                metadata_key: continent
            -   header: colo
                metadata_key: colo
            -   header: latitude
                metadata_key: latitude
            -   header: longitude
                metadata_key: longitude

    # Uncomment to enable customer JWT validation for search requests.
    # This allows customers to use their own identity provider (IdP) for authentication.
    # The JWT must include an "orak" claim containing the collection's read API key.
    # Additional claims can be accessed by the beforeSearch hook to apply custom restrictions.
    # Example JWT claim: {"orak":"c1_my-read-api-key", "country": "US", "iss":"https://issuer"}
    jwt:
        providers:
            -   name: "Supabase"
                jwks_url: https://czjqejhvicpcufovzrtj.supabase.co/auth/v1/.well-known/jwks.json
                issuers:
                    - https://czjqejhvicpcufovzrtj.supabase.co/auth/v1
                audiences:
                    - authenticated
                refresh_interval: 1h
            # Add more providers as needed for different customers:
            # - name: "auth0-production"
            #   jwks_url: https://your-tenant.auth0.com/.well-known/jwks.json
            #   issuers:
            #       - https://your-tenant.auth0.com/
            #   audiences:
            #       - https://api.yourservice.com

ai_server:
    scheme: http
    host: 0.0.0.0
    port: 50051
    api_key: ""
    max_connections: 15
    total_threads: 12

    embeddings:
        default_model_group: small
        dynamically_load_models: false
        execution_providers:
            #- CUDAExecutionProvider
            - CPUExecutionProvider
        total_threads: 8
        # automatic_embeddings_selector:
        #     model: "gpt-4.1"
        #     provider: openai

    llm:
        local: true
        port: 8000
        host: 0.0.0.0
        model: "Qwen/Qwen2.5-3B-Instruct"

      # Remote LLM configuration
      # Uncomment the lines below and comment the above to use remote LLM
      # local: false
      # host: "https://api.groq.com/openai/v1"
      # model: "openai/gpt-oss-120b"
      # api_key: "your-api-key-here"


    remote_llms:
    # - provider: openai
    #   api_key: sk-
    #   default_model: "gpt-4.1"
    # - provider: together
    #   api_key: "sk-"
    #   default_model: "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF"
    # - provider: fireworks
    #   api_key: "sk-"
    #   default_model: "accounts/fireworks/models/llama-v3p1-8b-instruct"
